{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Financial Dataset\n",
    "- https://www.kaggle.com/datasets/ealaxi/paysim1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "df['isFlaggedFraud'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nunique for categorical columns\n",
    "df.select_dtypes('object').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if checking the nameOrig and nameDest columns for equality is a good feature\n",
    "orig_is_dest = df['nameOrig'] == df['nameDest']\n",
    "orig_is_dest.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How common is fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df, x='isFraud', hue='isFraud', stat='probability')\n",
    "df['isFraud'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do fraudulent transactions compare to non-fradulent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df, y='amount', x='isFraud', hue='isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, y='amount', x='isFraud', hue='isFraud', errorbar=('ci',68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(df, y='amount', x='isFraud', hue='isFraud', errorbar=('ci',68), estimator='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transaction Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often is each type of transaction fraudulent?\n",
    "df.groupby(['type'])['isFraud'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How correct was pre-existing flag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['isFraud'], df['isFlaggedFraud'] ))\n",
    "ConfusionMatrixDisplay.from_predictions(df['isFraud'], df['isFlaggedFraud'],cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recall is terrible for fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['nameOrig','nameDest','isFlaggedFraud']\n",
    "df_ml = df.drop(columns=drop_cols, errors='ignore')\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_selector = make_column_selector(dtype_include=\"number\")\n",
    "num_pipe = Pipeline(\n",
    "    [\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_selector = make_column_selector(dtype_include=[\"object\",'category'])\n",
    "cat_pipe = Pipeline(\n",
    "    [\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipe, num_selector),\n",
    "        ('cat', cat_pipe, cat_selector)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data\n",
    "X = df_ml.drop(columns='isFraud')\n",
    "y = df_ml['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"{X_train.shape=}, {X_test.shape=}\")\n",
    "print(y_train.value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit preprocessor on training data\n",
    "X_train_tf = preprocessor.fit_transform(X_train)\n",
    "X_test_tf = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dojo_ds\n",
    "import dojo_ds as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n",
    "clf_pipe = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ]\n",
    ")\n",
    "clf_pipe.fit(X_train, y_train)\n",
    "ds.evaluate.evaluate_classification(clf_pipe, X_train=X_train, y_train=y_train,\n",
    "                                    X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_features = cat_selector(X_train)\n",
    "# cat_features\n",
    "\n",
    "# cat_features_mask = np.zeros_like(X_train_tf.columns, dtype=bool)\n",
    "# cat_features_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Make a mask for the cat features\n",
    "# for cat in cat_features:\n",
    "#     for i in range(len(X_train_tf.columns)):\n",
    "#         if X_train_tf.columns[i].startswith(cat):\n",
    "#             cat_features_mask[i] = True\n",
    "# cat_features_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "# from imblearn.pipeline import Pipeline as imbpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categories to category dtype for SMOTENC to work\n",
    "cat_cols = cat_selector(X_train)\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing out the encoder for SMOTENC\n",
    "ohe = preprocessor.named_transformers_['cat'].named_steps['encoder']\n",
    "ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SMOTENC for categorical features\n",
    "smote = SMOTENC(categorical_features='auto',\n",
    "                categorical_encoder=ohe,\n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the smote on the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smote.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess (Permanently change the data types of the categorical columns)\n",
    "X_train_smote_tf = preprocessor.fit_transform(X_train_smote)\n",
    "X_test_tf = preprocessor.transform(X_test)\n",
    "X_train_smote_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest (Smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf_rf.fit(X_train_smote_tf, y_train_smote)\n",
    "\n",
    "ds.evaluate.evaluate_classification(clf_rf, X_train=X_train_smote_tf, y_train=y_train_smote,\n",
    "                                    X_test=X_test_tf, y_test=y_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "\n",
    "y_pred = clf_rf.predict_proba(X_test_tf)[:,1]\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg (Smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_smote_tf, y_train_smote)\n",
    "ds.evaluate.evaluate_classification(clf, X_train=X_train_smote_tf, y_train=y_train_smote,\n",
    "                                    X_test=X_test_tf, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# y_pred = clf.predict_proba(X_test_tf)[:,1]\n",
    "# roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# svm = LinearSVC()\n",
    "# svm.fit(X_train_smote_tf, y_train_smote)\n",
    "# ds.evaluate.evaluate_classification(svm, X_train=X_train_smote_tf, y_train=y_train_smote,\n",
    "#                                     X_test=X_test_tf, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would isolation forest identify the correct fraudulent transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IsolatonForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.001, random_state=42)\n",
    "iso_forest.fit(X_train_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_train = iso_forest.predict(X_train_tf)\n",
    "\n",
    "print(f\"Classification Report for Train Data\")\n",
    "print(classification_report(y_train, pred_train==-1))\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, pred_train==-1, cmap='Greens')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Classification Report for Test Data\")\n",
    "pred_test = iso_forest.predict(X_test_tf)\n",
    "print(classification_report(y_test, pred_test==-1))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred_test==-1, cmap='Reds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.evaluate.evaluate_classification(iso_forest, X_train=X_train_tf, y_train=y_train,\n",
    "#                                     X_test=X_test_tf, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for SHAP (decided to use smoted data for equal representation of fraud and non-fraud in the sample)\n",
    "X_shap = shap.sample(X_train_smote_tf, 500, random_state=321)\n",
    "y_shap =  y_train_smote.loc[X_shap.index]\n",
    "print(y_shap.value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(clf_rf, X_shap)\n",
    "shap_values = explainer(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,1], X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[:,:,1], X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # force plot\n",
    "# shap.force_plot(explainer.expected_value, shap_values[:,:,1], X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
